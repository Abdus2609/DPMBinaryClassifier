{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d387a9ae-3618-4615-bc29-0540fa535ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (4.38.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers) (0.21.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: requests in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: filelock in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->transformers) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->transformers) (3.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f13176-f951-44cd-a0a9-f8fd659a6bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3109378/1267011614.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "\n",
    "file_path = \"train_data/dontpatronizeme_pcl.tsv\"\n",
    "train_filepath = \"dev_data/train_semeval_parids-labels.csv\"\n",
    "dev_filepath = \"dev_data/dev_semeval_parids-labels.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep='\\t', header=2, names=['id', 'paragraph-id', 'keyword', 'countrycode', \"paragraph\", \"label\"])\n",
    "df_filtered = df[df['paragraph'].notna()]\n",
    "\n",
    "train_df = pd.read_csv(train_filepath)\n",
    "dev_df = pd.read_csv(dev_filepath)\n",
    "\n",
    "train_data = df_filtered[df_filtered['id'].isin(train_df['par_id'])]\n",
    "dev_data = df_filtered[df_filtered['id'].isin(dev_df['par_id'])]\n",
    "\n",
    "train_data_shuffled = shuffle(train_data, random_state=42)\n",
    "dev_data_shuffled = shuffle(dev_data, random_state=42)\n",
    "\n",
    "X_train = train_data_shuffled['paragraph'].to_numpy()\n",
    "X_dev = dev_data_shuffled['paragraph'].to_numpy()\n",
    "\n",
    "y_train = [0 if int(x) <= 1 else 1 for x in train_data_shuffled['label']]\n",
    "y_dev = [0 if int(x) <= 1 else 1 for x in dev_data_shuffled['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f834d797-6ac4-40fb-8bb5-b12f37bcebeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph-id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>4823</td>\n",
       "      <td>@@8781228</td>\n",
       "      <td>disabled</td>\n",
       "      <td>gb</td>\n",
       "      <td>As well as lying about helping flood victims ,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8324</th>\n",
       "      <td>8325</td>\n",
       "      <td>@@14942580</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>ng</td>\n",
       "      <td>Betty Abah is passionate about this initiative...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>2384</td>\n",
       "      <td>@@7600715</td>\n",
       "      <td>in-need</td>\n",
       "      <td>sg</td>\n",
       "      <td>\" He liked to help people so I thought this co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>4289</td>\n",
       "      <td>@@8869471</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>ng</td>\n",
       "      <td>\" The airlines are relatively small , weak and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>5508</td>\n",
       "      <td>@@23720891</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ie</td>\n",
       "      <td>In general , people live inside their own bubb...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>5847</td>\n",
       "      <td>@@19919480</td>\n",
       "      <td>homeless</td>\n",
       "      <td>my</td>\n",
       "      <td>Last year , a record 85 homes were demolished ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>5291</td>\n",
       "      <td>@@21695353</td>\n",
       "      <td>homeless</td>\n",
       "      <td>pk</td>\n",
       "      <td>\" As a country , we can look for the missed op...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5491</th>\n",
       "      <td>5492</td>\n",
       "      <td>@@14069020</td>\n",
       "      <td>immigrant</td>\n",
       "      <td>hk</td>\n",
       "      <td>Any opening in which the speakers can revert t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>@@24188457</td>\n",
       "      <td>in-need</td>\n",
       "      <td>ke</td>\n",
       "      <td>Dennis insisted that his initiative was not in...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7421</th>\n",
       "      <td>7422</td>\n",
       "      <td>@@1431279</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>ca</td>\n",
       "      <td>Developing something like this for commercial ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8375 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id paragraph-id     keyword countrycode  \\\n",
       "4822  4823    @@8781228    disabled          gb   \n",
       "8324  8325   @@14942580  vulnerable          ng   \n",
       "2383  2384    @@7600715     in-need          sg   \n",
       "4288  4289    @@8869471  vulnerable          ng   \n",
       "5507  5508   @@23720891     refugee          ie   \n",
       "...    ...          ...         ...         ...   \n",
       "5846  5847   @@19919480    homeless          my   \n",
       "5290  5291   @@21695353    homeless          pk   \n",
       "5491  5492   @@14069020   immigrant          hk   \n",
       "879    880   @@24188457     in-need          ke   \n",
       "7421  7422    @@1431279    hopeless          ca   \n",
       "\n",
       "                                              paragraph  label  \n",
       "4822  As well as lying about helping flood victims ,...      0  \n",
       "8324  Betty Abah is passionate about this initiative...      4  \n",
       "2383  \" He liked to help people so I thought this co...      1  \n",
       "4288  \" The airlines are relatively small , weak and...      0  \n",
       "5507  In general , people live inside their own bubb...      3  \n",
       "...                                                 ...    ...  \n",
       "5846  Last year , a record 85 homes were demolished ...      0  \n",
       "5290  \" As a country , we can look for the missed op...      0  \n",
       "5491  Any opening in which the speakers can revert t...      0  \n",
       "879   Dennis insisted that his initiative was not in...      3  \n",
       "7421  Developing something like this for commercial ...      0  \n",
       "\n",
       "[8375 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd52e609-3775-419e-9f5c-2eb7c8bef024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph-id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10056</th>\n",
       "      <td>10057</td>\n",
       "      <td>@@4197415</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>ca</td>\n",
       "      <td>Darte acknowledged cutting back to the Windsor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9650</th>\n",
       "      <td>9651</td>\n",
       "      <td>@@25216962</td>\n",
       "      <td>migrant</td>\n",
       "      <td>bd</td>\n",
       "      <td>UNITED States President Donald Trump has defen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>9120</td>\n",
       "      <td>@@22467955</td>\n",
       "      <td>immigrant</td>\n",
       "      <td>ca</td>\n",
       "      <td>Saraswat said most immigrants have unique livi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>8505</td>\n",
       "      <td>@@10179731</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>pk</td>\n",
       "      <td>He said some elements were bent upon spreading...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>1283</td>\n",
       "      <td>@@3208839</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ph</td>\n",
       "      <td>\" Stateless \" is the story of a forgotten grou...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>9978</td>\n",
       "      <td>@@13589752</td>\n",
       "      <td>homeless</td>\n",
       "      <td>in</td>\n",
       "      <td>One response to marital infidelity is divorce ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9384</th>\n",
       "      <td>9385</td>\n",
       "      <td>@@1955909</td>\n",
       "      <td>homeless</td>\n",
       "      <td>tz</td>\n",
       "      <td>Various other areas have been experiencing exc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9423</th>\n",
       "      <td>9424</td>\n",
       "      <td>@@18374692</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>ca</td>\n",
       "      <td>Chris Selley : Maybe liquor retail in Ontario ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9594</th>\n",
       "      <td>9595</td>\n",
       "      <td>@@1065878</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>us</td>\n",
       "      <td>Robin Wauters is the European Editor of The Ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9136</th>\n",
       "      <td>9137</td>\n",
       "      <td>@@52188</td>\n",
       "      <td>disabled</td>\n",
       "      <td>ie</td>\n",
       "      <td>\" It ranges from members of the Oireachtas , t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2093 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id paragraph-id        keyword countrycode  \\\n",
       "10056  10057    @@4197415  poor-families          ca   \n",
       "9650    9651   @@25216962        migrant          bd   \n",
       "9119    9120   @@22467955      immigrant          ca   \n",
       "8504    8505   @@10179731       hopeless          pk   \n",
       "1282    1283    @@3208839        refugee          ph   \n",
       "...      ...          ...            ...         ...   \n",
       "9977    9978   @@13589752       homeless          in   \n",
       "9384    9385    @@1955909       homeless          tz   \n",
       "9423    9424   @@18374692       hopeless          ca   \n",
       "9594    9595    @@1065878       hopeless          us   \n",
       "9136    9137      @@52188       disabled          ie   \n",
       "\n",
       "                                               paragraph  label  \n",
       "10056  Darte acknowledged cutting back to the Windsor...      0  \n",
       "9650   UNITED States President Donald Trump has defen...      0  \n",
       "9119   Saraswat said most immigrants have unique livi...      0  \n",
       "8504   He said some elements were bent upon spreading...      0  \n",
       "1282   \" Stateless \" is the story of a forgotten grou...      4  \n",
       "...                                                  ...    ...  \n",
       "9977   One response to marital infidelity is divorce ...      0  \n",
       "9384   Various other areas have been experiencing exc...      0  \n",
       "9423   Chris Selley : Maybe liquor retail in Ontario ...      0  \n",
       "9594   Robin Wauters is the European Editor of The Ne...      0  \n",
       "9136   \" It ranges from members of the Oireachtas , t...      0  \n",
       "\n",
       "[2093 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5bee13-afff-41c7-8a85-6384b6640f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8375\n",
      "2093\n",
      "8375\n",
      "2093\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_dev))\n",
    "print(len(y_train))\n",
    "print(len(y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e374b79-8296-4d75-9a40-7755a4d9310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 7z175i45\n",
      "Sweep URL: https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'eval/f1_score',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "\n",
    "        'epochs': {\n",
    "            'values' : [3, 5, 7]\n",
    "        },\n",
    "\n",
    "        'batch_size': {\n",
    "            'values': [8, 16, 32]\n",
    "        },\n",
    "\n",
    "        'warmup_steps': {\n",
    "            'values': [100, 500]\n",
    "        },\n",
    "\n",
    "        'learning_rate': {\n",
    "            'values': [1e-5, 2e-5, 3e-5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_defaults = {\n",
    "        'learning_rate': 2e-5,\n",
    "\n",
    "        'batch_size': 16,\n",
    "\n",
    "        'epochs': 5,\n",
    "\n",
    "        'warmup_steps': 500\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12be0a7e-f29e-42a9-a6e8-35938fbd3ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c33b3e0c-51a5-44cd-9d3b-b7e4b5fbdb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aea042a-2041-4cd7-9911-752dfcfa0f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (0.27.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from accelerate) (0.21.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: triton==2.2.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: networkx in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: sympy in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: filelock in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: jinja2 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: requests in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: transformers[torch] in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (4.38.2)\n",
      "Requirement already satisfied: requests in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: numpy>=1.17 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (1.26.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (0.21.3)\n",
      "Requirement already satisfied: filelock in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: torch in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from transformers[torch]) (0.27.2)\n",
      "Requirement already satisfied: psutil in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: jinja2 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (2.19.3)\n",
      "Requirement already satisfied: sympy in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: networkx in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.3.101)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from requests->transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /vol/bitbucket/aah120/myenv/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4505c6e7-0004-4b24-ac4e-e7cfc52e4a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    \n",
    "    return {\"f1_score\": f1, \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "def train():\n",
    "\n",
    "    wandb.init()\n",
    "\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    max_length = 300\n",
    "    dataset = CustomDataset(X_train, y_train, tokenizer, max_length)\n",
    "\n",
    "    train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',          \n",
    "        per_device_train_batch_size=wandb.config.batch_size,  \n",
    "        per_device_eval_batch_size=wandb.config.batch_size,\n",
    "        num_train_epochs=wandb.config.epochs,\n",
    "        learning_rate=wandb.config.learning_rate,\n",
    "        warmup_steps=wandb.config.warmup_steps,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        metric_for_best_model = 'eval/f1_score',\n",
    "        report_to=\"wandb\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "\n",
    "    dev_set = CustomDataset(X_dev, y_dev, tokenizer, max_length)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    results = trainer.evaluate(dev_set)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Call the garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    # Ensure CUDA is aware of the freed memory\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9e3ef5-07b1-4f82-acc3-8c912b1ff934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ojrxzq5p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_192038-ojrxzq5p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/ojrxzq5p' target=\"_blank\">upbeat-sweep-1</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/ojrxzq5p' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/ojrxzq5p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5866' max='5866' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5866/5866 22:06, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.187417</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.533835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.195380</td>\n",
       "      <td>0.564315</td>\n",
       "      <td>0.937313</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.511278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.198500</td>\n",
       "      <td>0.277517</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.937313</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.431161</td>\n",
       "      <td>0.584795</td>\n",
       "      <td>0.915224</td>\n",
       "      <td>0.478469</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.501787</td>\n",
       "      <td>0.591463</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.497436</td>\n",
       "      <td>0.729323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.506262</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.924776</td>\n",
       "      <td>0.520231</td>\n",
       "      <td>0.676692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.554268</td>\n",
       "      <td>0.581250</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.497326</td>\n",
       "      <td>0.699248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:22:14 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='262' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [262/262 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▇▇▁▂▄▂▂</td></tr><tr><td>eval/f1_score</td><td>▄▁█▄▅▄▃▅</td></tr><tr><td>eval/loss</td><td>▁▁▃▆▇▇██</td></tr><tr><td>eval/precision</td><td>█▇▆▁▂▃▂▅</td></tr><tr><td>eval/recall</td><td>▂▁▄█▇▆▆▄</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>███████▁</td></tr><tr><td>eval/steps_per_second</td><td>███████▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▁▆▁█▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▅▅▄▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▄▃▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91973</td></tr><tr><td>eval/f1_score</td><td>0.59024</td></tr><tr><td>eval/loss</td><td>0.56181</td></tr><tr><td>eval/precision</td><td>0.57346</td></tr><tr><td>eval/recall</td><td>0.60804</td></tr><tr><td>eval/runtime</td><td>8.1745</td></tr><tr><td>eval/samples_per_second</td><td>256.04</td></tr><tr><td>eval/steps_per_second</td><td>32.051</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>5866</td></tr><tr><td>train/grad_norm</td><td>0.00643</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0275</td></tr><tr><td>train/total_flos</td><td>7230415134600000.0</td></tr><tr><td>train/train_loss</td><td>0.15423</td></tr><tr><td>train/train_runtime</td><td>1327.0847</td></tr><tr><td>train/train_samples_per_second</td><td>35.341</td></tr><tr><td>train/train_steps_per_second</td><td>4.42</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-sweep-1</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/ojrxzq5p' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/ojrxzq5p</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_192038-ojrxzq5p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qzgbpbfm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabdussamad2609\u001b[0m (\u001b[33meli-carried\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_194316-qzgbpbfm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/qzgbpbfm' target=\"_blank\">sleek-sweep-2</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/qzgbpbfm' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/qzgbpbfm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2095' max='2095' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2095/2095 10:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.185348</td>\n",
       "      <td>0.564885</td>\n",
       "      <td>0.931940</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.556391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.172352</td>\n",
       "      <td>0.585551</td>\n",
       "      <td>0.934925</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>0.269382</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.930149</td>\n",
       "      <td>0.554795</td>\n",
       "      <td>0.609023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.367036</td>\n",
       "      <td>0.566879</td>\n",
       "      <td>0.918806</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.669173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.404814</td>\n",
       "      <td>0.555932</td>\n",
       "      <td>0.921791</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.616541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:10:45 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [131/131 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▇█▆▁▂▂</td></tr><tr><td>eval/f1_score</td><td>▃█▇▄▁▇</td></tr><tr><td>eval/loss</td><td>▁▁▄▆▇█</td></tr><tr><td>eval/precision</td><td>▇█▅▁▂▇</td></tr><tr><td>eval/recall</td><td>▁▂▄█▅▃</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█████▁</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▅▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▅▆▆████</td></tr><tr><td>train/grad_norm</td><td>▁█▁▁</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▅▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92021</td></tr><tr><td>eval/f1_score</td><td>0.58145</td></tr><tr><td>eval/loss</td><td>0.42291</td></tr><tr><td>eval/precision</td><td>0.58</td></tr><tr><td>eval/recall</td><td>0.58291</td></tr><tr><td>eval/runtime</td><td>7.9824</td></tr><tr><td>eval/samples_per_second</td><td>262.201</td></tr><tr><td>eval/steps_per_second</td><td>16.411</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>2095</td></tr><tr><td>train/grad_norm</td><td>0.1714</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.06</td></tr><tr><td>train/total_flos</td><td>5164582239000000.0</td></tr><tr><td>train/train_loss</td><td>0.15008</td></tr><tr><td>train/train_runtime</td><td>639.3443</td></tr><tr><td>train/train_samples_per_second</td><td>52.397</td></tr><tr><td>train/train_steps_per_second</td><td>3.277</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-sweep-2</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/qzgbpbfm' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/qzgbpbfm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_194316-qzgbpbfm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y4akm0qk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_195423-y4akm0qk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/y4akm0qk' target=\"_blank\">whole-sweep-3</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/y4akm0qk' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/y4akm0qk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5866' max='5866' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5866/5866 22:18, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.227098</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.927761</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.165414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.252400</td>\n",
       "      <td>0.184873</td>\n",
       "      <td>0.566929</td>\n",
       "      <td>0.934328</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.541353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.303286</td>\n",
       "      <td>0.593985</td>\n",
       "      <td>0.935522</td>\n",
       "      <td>0.593985</td>\n",
       "      <td>0.593985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.481039</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.924776</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.669173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.499122</td>\n",
       "      <td>0.575163</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.661654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.577101</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>0.925970</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.646617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.593384</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.639098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:22:25 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='262' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [262/262 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▄▇█▂▁▃▄▃</td></tr><tr><td>eval/f1_score</td><td>▁▇█▇▇▇▇█</td></tr><tr><td>eval/loss</td><td>▂▁▃▆▆▇██</td></tr><tr><td>eval/precision</td><td>█▄▄▁▁▂▂▅</td></tr><tr><td>eval/recall</td><td>▁▆▇████▇</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>███████▁</td></tr><tr><td>eval/steps_per_second</td><td>███████▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇████</td></tr><tr><td>train/grad_norm</td><td>▃▁█▁▅▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▅▅▄▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▄▃▂▂▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92594</td></tr><tr><td>eval/f1_score</td><td>0.61347</td></tr><tr><td>eval/loss</td><td>0.6227</td></tr><tr><td>eval/precision</td><td>0.60891</td></tr><tr><td>eval/recall</td><td>0.61809</td></tr><tr><td>eval/runtime</td><td>8.1308</td></tr><tr><td>eval/samples_per_second</td><td>257.417</td></tr><tr><td>eval/steps_per_second</td><td>32.223</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>5866</td></tr><tr><td>train/grad_norm</td><td>0.01463</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0055</td></tr><tr><td>train/total_flos</td><td>7230415134600000.0</td></tr><tr><td>train/train_loss</td><td>0.12728</td></tr><tr><td>train/train_runtime</td><td>1339.0569</td></tr><tr><td>train/train_samples_per_second</td><td>35.025</td></tr><tr><td>train/train_steps_per_second</td><td>4.381</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-sweep-3</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/y4akm0qk' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/y4akm0qk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_195423-y4akm0qk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nl0bqqcg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_201711-nl0bqqcg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/nl0bqqcg' target=\"_blank\">denim-sweep-4</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/nl0bqqcg' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/nl0bqqcg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2514' max='2514' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2514/2514 09:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.391500</td>\n",
       "      <td>0.184612</td>\n",
       "      <td>0.572549</td>\n",
       "      <td>0.934925</td>\n",
       "      <td>0.598361</td>\n",
       "      <td>0.548872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.210827</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.939104</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.406015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.280294</td>\n",
       "      <td>0.607774</td>\n",
       "      <td>0.933731</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.646617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:09:54 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='262' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [262/262 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▆█▆▁</td></tr><tr><td>eval/f1_score</td><td>▅▁█▅</td></tr><tr><td>eval/loss</td><td>▁▂▆█</td></tr><tr><td>eval/precision</td><td>▂█▁▂</td></tr><tr><td>eval/recall</td><td>▅▁█▅</td></tr><tr><td>eval/runtime</td><td>▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>███▁</td></tr><tr><td>eval/steps_per_second</td><td>███▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▆████</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▆████</td></tr><tr><td>train/grad_norm</td><td>▂▁▇▁█</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▄▄▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92212</td></tr><tr><td>eval/f1_score</td><td>0.57218</td></tr><tr><td>eval/loss</td><td>0.33292</td></tr><tr><td>eval/precision</td><td>0.5989</td></tr><tr><td>eval/recall</td><td>0.54774</td></tr><tr><td>eval/runtime</td><td>8.1758</td></tr><tr><td>eval/samples_per_second</td><td>256.001</td></tr><tr><td>eval/steps_per_second</td><td>32.046</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>2514</td></tr><tr><td>train/grad_norm</td><td>40.38631</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1722</td></tr><tr><td>train/total_flos</td><td>3098749343400000.0</td></tr><tr><td>train/train_loss</td><td>0.25795</td></tr><tr><td>train/train_runtime</td><td>588.2387</td></tr><tr><td>train/train_samples_per_second</td><td>34.17</td></tr><tr><td>train/train_steps_per_second</td><td>4.274</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denim-sweep-4</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/nl0bqqcg' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/nl0bqqcg</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_201711-nl0bqqcg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 22nz3kkj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_202731-22nz3kkj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/22nz3kkj' target=\"_blank\">skilled-sweep-5</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/22nz3kkj' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/22nz3kkj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5866' max='5866' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5866/5866 22:07, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>0.300731</td>\n",
       "      <td>0.058394</td>\n",
       "      <td>0.922985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.273100</td>\n",
       "      <td>0.236852</td>\n",
       "      <td>0.521401</td>\n",
       "      <td>0.926567</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.503759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.310047</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.937313</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>0.487240</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>0.912836</td>\n",
       "      <td>0.466321</td>\n",
       "      <td>0.676692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.632165</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.454054</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.595104</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.511278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.632087</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.923582</td>\n",
       "      <td>0.517483</td>\n",
       "      <td>0.556391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-5500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:22:14 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='262' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [262/262 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▄▅█▂▁▄▄▂</td></tr><tr><td>eval/f1_score</td><td>▁████▇█▇</td></tr><tr><td>eval/loss</td><td>▂▁▂▅▇▆▇█</td></tr><tr><td>eval/precision</td><td>█▂▃▁▁▂▂▂</td></tr><tr><td>eval/recall</td><td>▁▆▆██▆▇▆</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>███████▁</td></tr><tr><td>eval/steps_per_second</td><td>███████▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▁▁▁█▃▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▅▅▄▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▇▆▅▄▃▃▂▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91448</td></tr><tr><td>eval/f1_score</td><td>0.50959</td></tr><tr><td>eval/loss</td><td>0.7117</td></tr><tr><td>eval/precision</td><td>0.56024</td></tr><tr><td>eval/recall</td><td>0.46734</td></tr><tr><td>eval/runtime</td><td>8.1659</td></tr><tr><td>eval/samples_per_second</td><td>256.309</td></tr><tr><td>eval/steps_per_second</td><td>32.085</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>5866</td></tr><tr><td>train/grad_norm</td><td>0.0019</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0114</td></tr><tr><td>train/total_flos</td><td>7230415134600000.0</td></tr><tr><td>train/train_loss</td><td>0.14199</td></tr><tr><td>train/train_runtime</td><td>1328.0688</td></tr><tr><td>train/train_samples_per_second</td><td>35.314</td></tr><tr><td>train/train_steps_per_second</td><td>4.417</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-sweep-5</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/22nz3kkj' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/22nz3kkj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_202731-22nz3kkj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zufwzkia with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_205017-zufwzkia</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/zufwzkia' target=\"_blank\">lucky-sweep-6</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/zufwzkia' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/zufwzkia</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1050/1050 07:51, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.192546</td>\n",
       "      <td>0.446602</td>\n",
       "      <td>0.931940</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.345865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.153643</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>0.942090</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.466165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.162460</td>\n",
       "      <td>0.615970</td>\n",
       "      <td>0.939701</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.609023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.185510</td>\n",
       "      <td>0.644195</td>\n",
       "      <td>0.943284</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.646617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.207403</td>\n",
       "      <td>0.628975</td>\n",
       "      <td>0.937313</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.669173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:07:58 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▄█▇█▆▁</td></tr><tr><td>eval/f1_score</td><td>▁▅▇█▇▆</td></tr><tr><td>eval/loss</td><td>▄▁▂▃▅█</td></tr><tr><td>eval/precision</td><td>▃█▃▄▁▂</td></tr><tr><td>eval/recall</td><td>▁▄▇██▆</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█████▁</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>train/epoch</td><td>▁▃▃▅▆████</td></tr><tr><td>train/global_step</td><td>▁▃▃▅▆████</td></tr><tr><td>train/grad_norm</td><td>▁█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92308</td></tr><tr><td>eval/f1_score</td><td>0.57963</td></tr><tr><td>eval/loss</td><td>0.25102</td></tr><tr><td>eval/precision</td><td>0.60326</td></tr><tr><td>eval/recall</td><td>0.55779</td></tr><tr><td>eval/runtime</td><td>7.6889</td></tr><tr><td>eval/samples_per_second</td><td>272.212</td></tr><tr><td>eval/steps_per_second</td><td>8.584</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>1050</td></tr><tr><td>train/grad_norm</td><td>40.53864</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.118</td></tr><tr><td>train/total_flos</td><td>5164582239000000.0</td></tr><tr><td>train/train_loss</td><td>0.18176</td></tr><tr><td>train/train_runtime</td><td>471.929</td></tr><tr><td>train/train_samples_per_second</td><td>70.985</td></tr><tr><td>train/train_steps_per_second</td><td>2.225</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lucky-sweep-6</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/zufwzkia' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/zufwzkia</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_205017-zufwzkia/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fj5un3c1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_205837-fj5un3c1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/fj5un3c1' target=\"_blank\">lemon-sweep-7</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/fj5un3c1' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/fj5un3c1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/630 04:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.195322</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.927164</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.218045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.155583</td>\n",
       "      <td>0.547085</td>\n",
       "      <td>0.939701</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.458647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>0.169644</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.935522</td>\n",
       "      <td>0.577640</td>\n",
       "      <td>0.699248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:04:34 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▅█▇▁</td></tr><tr><td>eval/f1_score</td><td>▁▆█▆</td></tr><tr><td>eval/loss</td><td>▇▁▃█</td></tr><tr><td>eval/precision</td><td>▅█▃▁</td></tr><tr><td>eval/recall</td><td>▁▅█▆</td></tr><tr><td>eval/runtime</td><td>▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>███▁</td></tr><tr><td>eval/steps_per_second</td><td>███▁</td></tr><tr><td>train/epoch</td><td>▁▅▆███</td></tr><tr><td>train/global_step</td><td>▁▅▆███</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91352</td></tr><tr><td>eval/f1_score</td><td>0.56386</td></tr><tr><td>eval/loss</td><td>0.20335</td></tr><tr><td>eval/precision</td><td>0.54167</td></tr><tr><td>eval/recall</td><td>0.58794</td></tr><tr><td>eval/runtime</td><td>7.6531</td></tr><tr><td>eval/samples_per_second</td><td>273.484</td></tr><tr><td>eval/steps_per_second</td><td>8.624</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>630</td></tr><tr><td>train/grad_norm</td><td>5.97641</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.251</td></tr><tr><td>train/total_flos</td><td>3098749343400000.0</td></tr><tr><td>train/train_loss</td><td>0.22886</td></tr><tr><td>train/train_runtime</td><td>267.9672</td></tr><tr><td>train/train_samples_per_second</td><td>75.009</td></tr><tr><td>train/train_steps_per_second</td><td>2.351</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-sweep-7</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/fj5un3c1' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/fj5un3c1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_205837-fj5un3c1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4dh09rs7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_210336-4dh09rs7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/4dh09rs7' target=\"_blank\">zesty-sweep-8</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/4dh09rs7' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/4dh09rs7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1470' max='1470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1470/1470 10:05, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.197018</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.927164</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.187970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.170890</td>\n",
       "      <td>0.589091</td>\n",
       "      <td>0.932537</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.609023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.170487</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.935522</td>\n",
       "      <td>0.591241</td>\n",
       "      <td>0.609023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.283618</td>\n",
       "      <td>0.580838</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>0.482587</td>\n",
       "      <td>0.729323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.562319</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.457547</td>\n",
       "      <td>0.729323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.397168</td>\n",
       "      <td>0.579926</td>\n",
       "      <td>0.932537</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.586466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.405095</td>\n",
       "      <td>0.575646</td>\n",
       "      <td>0.931343</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.586466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:10:12 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▆▇█▃▁▇▇▅</td></tr><tr><td>eval/f1_score</td><td>▁███▇█▇▇</td></tr><tr><td>eval/loss</td><td>▂▁▁▄▇▆▇█</td></tr><tr><td>eval/precision</td><td>█▅▆▂▁▅▅▇</td></tr><tr><td>eval/recall</td><td>▁▆▆██▆▆▅</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>███████▁</td></tr><tr><td>eval/steps_per_second</td><td>███████▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▃▅▅▆▇███</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▅▅▆▇███</td></tr><tr><td>train/grad_norm</td><td>▁█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92451</td></tr><tr><td>eval/f1_score</td><td>0.57297</td></tr><tr><td>eval/loss</td><td>0.46716</td></tr><tr><td>eval/precision</td><td>0.61988</td></tr><tr><td>eval/recall</td><td>0.53266</td></tr><tr><td>eval/runtime</td><td>7.6555</td></tr><tr><td>eval/samples_per_second</td><td>273.398</td></tr><tr><td>eval/steps_per_second</td><td>8.621</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>1470</td></tr><tr><td>train/grad_norm</td><td>22.68005</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.1023</td></tr><tr><td>train/total_flos</td><td>7230415134600000.0</td></tr><tr><td>train/train_loss</td><td>0.139</td></tr><tr><td>train/train_runtime</td><td>605.6819</td></tr><tr><td>train/train_samples_per_second</td><td>77.433</td></tr><tr><td>train/train_steps_per_second</td><td>2.427</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zesty-sweep-8</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/4dh09rs7' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/4dh09rs7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_210336-4dh09rs7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1ercna7f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_211410-1ercna7f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/1ercna7f' target=\"_blank\">ethereal-sweep-9</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/1ercna7f' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/1ercna7f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1050/1050 07:51, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.200259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.920597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.171078</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.936716</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.593985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.182954</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.937910</td>\n",
       "      <td>0.623932</td>\n",
       "      <td>0.548872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.254720</td>\n",
       "      <td>0.599222</td>\n",
       "      <td>0.938507</td>\n",
       "      <td>0.620968</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.320334</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.931343</td>\n",
       "      <td>0.559211</td>\n",
       "      <td>0.639098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/aah120/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:07:58 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██▅▂</td></tr><tr><td>eval/f1_score</td><td>▁█████</td></tr><tr><td>eval/loss</td><td>▂▁▁▄▆█</td></tr><tr><td>eval/precision</td><td>▁███▇█</td></tr><tr><td>eval/recall</td><td>▁█▇▇█▇</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█████▁</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>train/epoch</td><td>▁▃▃▅▆████</td></tr><tr><td>train/global_step</td><td>▁▃▃▅▆████</td></tr><tr><td>train/grad_norm</td><td>█▁</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92308</td></tr><tr><td>eval/f1_score</td><td>0.57743</td></tr><tr><td>eval/loss</td><td>0.36994</td></tr><tr><td>eval/precision</td><td>0.6044</td></tr><tr><td>eval/recall</td><td>0.55276</td></tr><tr><td>eval/runtime</td><td>7.6455</td></tr><tr><td>eval/samples_per_second</td><td>273.757</td></tr><tr><td>eval/steps_per_second</td><td>8.633</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>1050</td></tr><tr><td>train/grad_norm</td><td>0.59488</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0726</td></tr><tr><td>train/total_flos</td><td>5164582239000000.0</td></tr><tr><td>train/train_loss</td><td>0.14724</td></tr><tr><td>train/train_runtime</td><td>471.754</td></tr><tr><td>train/train_samples_per_second</td><td>71.012</td></tr><tr><td>train/train_steps_per_second</td><td>2.226</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-9</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/1ercna7f' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/1ercna7f</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_211410-1ercna7f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6y51b3kc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_212233-6y51b3kc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/6y51b3kc' target=\"_blank\">scarlet-sweep-10</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/6y51b3kc' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/6y51b3kc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2514' max='2514' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2514/2514 09:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.225572</td>\n",
       "      <td>0.375691</td>\n",
       "      <td>0.932537</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.255639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.245700</td>\n",
       "      <td>0.208574</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.938507</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.326886</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.934328</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>0.676692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:09:56 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='262' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [262/262 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▅█▆▁</td></tr><tr><td>eval/f1_score</td><td>▁▇█▇</td></tr><tr><td>eval/loss</td><td>▂▁▇█</td></tr><tr><td>eval/precision</td><td>█▄▁▂</td></tr><tr><td>eval/recall</td><td>▁▆█▇</td></tr><tr><td>eval/runtime</td><td>▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>███▁</td></tr><tr><td>eval/steps_per_second</td><td>███▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▆████</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▆████</td></tr><tr><td>train/grad_norm</td><td>▂▁█▁▃</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▅▄▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.9226</td></tr><tr><td>eval/f1_score</td><td>0.59901</td></tr><tr><td>eval/loss</td><td>0.35724</td></tr><tr><td>eval/precision</td><td>0.59024</td></tr><tr><td>eval/recall</td><td>0.60804</td></tr><tr><td>eval/runtime</td><td>8.0656</td></tr><tr><td>eval/samples_per_second</td><td>259.496</td></tr><tr><td>eval/steps_per_second</td><td>32.484</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>2514</td></tr><tr><td>train/grad_norm</td><td>19.25789</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1488</td></tr><tr><td>train/total_flos</td><td>3098749343400000.0</td></tr><tr><td>train/train_loss</td><td>0.24361</td></tr><tr><td>train/train_runtime</td><td>589.1824</td></tr><tr><td>train/train_samples_per_second</td><td>34.115</td></tr><tr><td>train/train_steps_per_second</td><td>4.267</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scarlet-sweep-10</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/6y51b3kc' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/6y51b3kc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_212233-6y51b3kc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mjbfqgab with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_213254-mjbfqgab</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/mjbfqgab' target=\"_blank\">daily-sweep-11</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/mjbfqgab' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/mjbfqgab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1470' max='1470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1470/1470 10:06, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.197018</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.927164</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.187970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.170890</td>\n",
       "      <td>0.589091</td>\n",
       "      <td>0.932537</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.609023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.170487</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.935522</td>\n",
       "      <td>0.591241</td>\n",
       "      <td>0.609023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.283618</td>\n",
       "      <td>0.580838</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>0.482587</td>\n",
       "      <td>0.729323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.562319</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.457547</td>\n",
       "      <td>0.729323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.397168</td>\n",
       "      <td>0.579926</td>\n",
       "      <td>0.932537</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.586466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.405095</td>\n",
       "      <td>0.575646</td>\n",
       "      <td>0.931343</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.586466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:10:14 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.017 MB uploaded\\r'), FloatProgress(value=0.16553716253749584, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▆▇█▃▁▇▇▅</td></tr><tr><td>eval/f1_score</td><td>▁███▇█▇▇</td></tr><tr><td>eval/loss</td><td>▂▁▁▄▇▆▇█</td></tr><tr><td>eval/precision</td><td>█▅▆▂▁▅▅▇</td></tr><tr><td>eval/recall</td><td>▁▆▆██▆▆▅</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>███████▁</td></tr><tr><td>eval/steps_per_second</td><td>███████▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▃▅▅▆▇███</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▅▅▆▇███</td></tr><tr><td>train/grad_norm</td><td>▁█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92451</td></tr><tr><td>eval/f1_score</td><td>0.57297</td></tr><tr><td>eval/loss</td><td>0.46716</td></tr><tr><td>eval/precision</td><td>0.61988</td></tr><tr><td>eval/recall</td><td>0.53266</td></tr><tr><td>eval/runtime</td><td>7.6553</td></tr><tr><td>eval/samples_per_second</td><td>273.404</td></tr><tr><td>eval/steps_per_second</td><td>8.621</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>1470</td></tr><tr><td>train/grad_norm</td><td>22.68005</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.1023</td></tr><tr><td>train/total_flos</td><td>7230415134600000.0</td></tr><tr><td>train/train_loss</td><td>0.139</td></tr><tr><td>train/train_runtime</td><td>607.3007</td></tr><tr><td>train/train_samples_per_second</td><td>77.227</td></tr><tr><td>train/train_steps_per_second</td><td>2.421</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">daily-sweep-11</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/mjbfqgab' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/mjbfqgab</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_213254-mjbfqgab/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 36s9xlgv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_214330-36s9xlgv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/36s9xlgv' target=\"_blank\">happy-sweep-12</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/36s9xlgv' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/36s9xlgv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/630 04:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.214314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.920597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.166089</td>\n",
       "      <td>0.315152</td>\n",
       "      <td>0.932537</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.195489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.322600</td>\n",
       "      <td>0.168329</td>\n",
       "      <td>0.624161</td>\n",
       "      <td>0.933134</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.699248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/aah120/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:04:37 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▂██▁</td></tr><tr><td>eval/f1_score</td><td>▁▅█▇</td></tr><tr><td>eval/loss</td><td>█▁▁▅</td></tr><tr><td>eval/precision</td><td>▁█▆▆</td></tr><tr><td>eval/recall</td><td>▁▃█▇</td></tr><tr><td>eval/runtime</td><td>▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>███▁</td></tr><tr><td>eval/steps_per_second</td><td>███▁</td></tr><tr><td>train/epoch</td><td>▁▅▆███</td></tr><tr><td>train/global_step</td><td>▁▅▆███</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91782</td></tr><tr><td>eval/f1_score</td><td>0.57426</td></tr><tr><td>eval/loss</td><td>0.19393</td></tr><tr><td>eval/precision</td><td>0.56585</td></tr><tr><td>eval/recall</td><td>0.58291</td></tr><tr><td>eval/runtime</td><td>7.6398</td></tr><tr><td>eval/samples_per_second</td><td>273.958</td></tr><tr><td>eval/steps_per_second</td><td>8.639</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>630</td></tr><tr><td>train/grad_norm</td><td>6.91404</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.3226</td></tr><tr><td>train/total_flos</td><td>3098749343400000.0</td></tr><tr><td>train/train_loss</td><td>0.29262</td></tr><tr><td>train/train_runtime</td><td>270.0782</td></tr><tr><td>train/train_samples_per_second</td><td>74.423</td></tr><tr><td>train/train_steps_per_second</td><td>2.333</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-sweep-12</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/36s9xlgv' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/36s9xlgv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_214330-36s9xlgv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s5q17aqq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_214838-s5q17aqq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/s5q17aqq' target=\"_blank\">generous-sweep-13</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/s5q17aqq' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/s5q17aqq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/630 04:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.203539</td>\n",
       "      <td>0.454936</td>\n",
       "      <td>0.924179</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.398496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.159455</td>\n",
       "      <td>0.614815</td>\n",
       "      <td>0.937910</td>\n",
       "      <td>0.605839</td>\n",
       "      <td>0.624060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>0.198272</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.933134</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.721805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:04:37 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▄█▇▁</td></tr><tr><td>eval/f1_score</td><td>▁▇█▆</td></tr><tr><td>eval/loss</td><td>▅▁▅█</td></tr><tr><td>eval/precision</td><td>▁█▄▃</td></tr><tr><td>eval/recall</td><td>▁▆█▆</td></tr><tr><td>eval/runtime</td><td>▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>███▁</td></tr><tr><td>eval/steps_per_second</td><td>███▁</td></tr><tr><td>train/epoch</td><td>▁▅▆███</td></tr><tr><td>train/global_step</td><td>▁▅▆███</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91543</td></tr><tr><td>eval/f1_score</td><td>0.58156</td></tr><tr><td>eval/loss</td><td>0.23641</td></tr><tr><td>eval/precision</td><td>0.54911</td></tr><tr><td>eval/recall</td><td>0.61809</td></tr><tr><td>eval/runtime</td><td>7.6128</td></tr><tr><td>eval/samples_per_second</td><td>274.932</td></tr><tr><td>eval/steps_per_second</td><td>8.67</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>630</td></tr><tr><td>train/grad_norm</td><td>11.09079</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2377</td></tr><tr><td>train/total_flos</td><td>3098749343400000.0</td></tr><tr><td>train/train_loss</td><td>0.21299</td></tr><tr><td>train/train_runtime</td><td>269.9932</td></tr><tr><td>train/train_samples_per_second</td><td>74.446</td></tr><tr><td>train/train_steps_per_second</td><td>2.333</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">generous-sweep-13</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/s5q17aqq' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/s5q17aqq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_214838-s5q17aqq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zi4nkngl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_215346-zi4nkngl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/zi4nkngl' target=\"_blank\">breezy-sweep-14</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/zi4nkngl' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/zi4nkngl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4190' max='4190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4190/4190 15:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.353800</td>\n",
       "      <td>0.187225</td>\n",
       "      <td>0.546185</td>\n",
       "      <td>0.932537</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.511278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.199604</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>0.941493</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.488722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.184600</td>\n",
       "      <td>0.294284</td>\n",
       "      <td>0.582996</td>\n",
       "      <td>0.938507</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.541353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.383098</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.924776</td>\n",
       "      <td>0.519553</td>\n",
       "      <td>0.699248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.415858</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>0.540373</td>\n",
       "      <td>0.654135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:16:04 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='262' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [262/262 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▅█▇▃▄▁</td></tr><tr><td>eval/f1_score</td><td>▁▄▆█▇▇</td></tr><tr><td>eval/loss</td><td>▁▁▃▅▆█</td></tr><tr><td>eval/precision</td><td>▄█▆▁▂▃</td></tr><tr><td>eval/recall</td><td>▂▁▃█▆▅</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█████▁</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇████</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▄▅▅▆▆▇████</td></tr><tr><td>train/grad_norm</td><td>▁▁█▁▃▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▄▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92021</td></tr><tr><td>eval/f1_score</td><td>0.59169</td></tr><tr><td>eval/loss</td><td>0.49224</td></tr><tr><td>eval/precision</td><td>0.57619</td></tr><tr><td>eval/recall</td><td>0.60804</td></tr><tr><td>eval/runtime</td><td>8.1026</td></tr><tr><td>eval/samples_per_second</td><td>258.312</td></tr><tr><td>eval/steps_per_second</td><td>32.335</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>4190</td></tr><tr><td>train/grad_norm</td><td>0.02674</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0673</td></tr><tr><td>train/total_flos</td><td>5164582239000000.0</td></tr><tr><td>train/train_loss</td><td>0.18509</td></tr><tr><td>train/train_runtime</td><td>957.7093</td></tr><tr><td>train/train_samples_per_second</td><td>34.979</td></tr><tr><td>train/train_steps_per_second</td><td>4.375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-sweep-14</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/zi4nkngl' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/zi4nkngl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_215346-zi4nkngl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9zc864jw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_221018-9zc864jw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/9zc864jw' target=\"_blank\">kind-sweep-15</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/9zc864jw' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/9zc864jw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2095' max='2095' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2095/2095 10:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.223452</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.904478</td>\n",
       "      <td>0.414013</td>\n",
       "      <td>0.488722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>0.165130</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.931940</td>\n",
       "      <td>0.569343</td>\n",
       "      <td>0.586466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.217800</td>\n",
       "      <td>0.235878</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.931940</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>0.533835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.351921</td>\n",
       "      <td>0.561873</td>\n",
       "      <td>0.921791</td>\n",
       "      <td>0.506024</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.407492</td>\n",
       "      <td>0.569395</td>\n",
       "      <td>0.927761</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.601504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "Total training took 0:10:44 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [131/131 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁██▅▇▅</td></tr><tr><td>eval/f1_score</td><td>▁█▇▇█▇</td></tr><tr><td>eval/loss</td><td>▂▁▃▆▇█</td></tr><tr><td>eval/precision</td><td>▁▇▇▄▆█</td></tr><tr><td>eval/recall</td><td>▁▆▃█▇▃</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█████▁</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▅▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▅▆▆████</td></tr><tr><td>train/grad_norm</td><td>▁▄█▁</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92164</td></tr><tr><td>eval/f1_score</td><td>0.56383</td></tr><tr><td>eval/loss</td><td>0.44147</td></tr><tr><td>eval/precision</td><td>0.59887</td></tr><tr><td>eval/recall</td><td>0.53266</td></tr><tr><td>eval/runtime</td><td>7.9653</td></tr><tr><td>eval/samples_per_second</td><td>262.764</td></tr><tr><td>eval/steps_per_second</td><td>16.446</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>2095</td></tr><tr><td>train/grad_norm</td><td>0.07918</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0502</td></tr><tr><td>train/total_flos</td><td>5164582239000000.0</td></tr><tr><td>train/train_loss</td><td>0.1678</td></tr><tr><td>train/train_runtime</td><td>637.5419</td></tr><tr><td>train/train_samples_per_second</td><td>52.546</td></tr><tr><td>train/train_steps_per_second</td><td>3.286</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-sweep-15</strong> at: <a href='https://wandb.ai/eli-carried/uncategorized/runs/9zc864jw' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/9zc864jw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240309_221018-9zc864jw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nrpdf4y4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vol/bitbucket/aah120/dpm-binary-classifier/wandb/run-20240309_222124-nrpdf4y4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eli-carried/uncategorized/runs/nrpdf4y4' target=\"_blank\">absurd-sweep-16</a></strong> to <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eli-carried/uncategorized' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/sweeps/7z175i45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eli-carried/uncategorized/runs/nrpdf4y4' target=\"_blank\">https://wandb.ai/eli-carried/uncategorized/runs/nrpdf4y4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_steps' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='93' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 93/630 00:27 < 02:39, 3.37 it/s, Epoch 0.44/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11abe8e5-9c05-48d2-a8a8-a2f8c1f750c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Call the garbage collector\n",
    "gc.collect()\n",
    "    \n",
    "# Ensure CUDA is aware of the freed memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "840b210a-cc0b-478c-bbdc-85487865ca8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[{'input_ids': tensor([    0, 20689, 15772,    11, 19531,  1469,  1182,    16,  1726,    30,\n",
      "           10,   346,     9,  2433,  2156,   217,   474,  1272,  2156,  2196,\n",
      "            8,  3766,  2156, 11902,  2156,  5263,     8, 24418,  1825,  2156,\n",
      "           79,    26,  2156,     8,    22,    11,   645,     7,   912,    82,\n",
      "           31, 11389,  4260,  2156,    52,   240,     7,   356,    23,   209,\n",
      "          743,   479,   318,    52,   109,   295,    75,   192,   106,    50,\n",
      "         1798,    59,    24,  2156,    24, 19958,   295,    75,   213,   409,\n",
      "          479,    22,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([    0,   133,  6458,    21,   373,    30,    49,   632,  1037, 15666,\n",
      "           36,   274,   791,  5944,  4839,     7,  1962,     5,  1079,     9,\n",
      "            5,  2837,  9321,    62,    13,     5,  5192,   479,   635, 13262,\n",
      "          102,    32,    67, 20497,    11,   240,     9,     5,   472,    13,\n",
      "           49,  4096,  5267,   597,  3666,   815,   671,  2985,   914,   136,\n",
      "         9758,   726,  7746,   352,     7,    28,   702,    11, 14794,    15,\n",
      "          395,   479,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([    0,  3762,     9,     5,   483,  7601,     9,     5, 13387,   892,\n",
      "         2156,  6020,  9894,   808,   381,  7399,  3648,     9,     5,   835,\n",
      "            9,  1909,  1309,    23, 16659,  1821,   928,  2156,   161,  4832,\n",
      "           22,  1216, 12648,  3926,  4227,     5,   913,     9,   689,  2474,\n",
      "            8,  1986,   420,     5,  7183,  2156,    19,  2245, 30426,  6592,\n",
      "          350,  3214,    13,  2129,  1232,     8,  1822,   479,     2,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([    0, 13863,  7077,  1419,     5,  2604,  8825,    15,     5,   659,\n",
      "            9,  6242,    82,  2156,     5,   168,   202,   473,    45,    33,\n",
      "        10280,  6732,    15,     5,   346,    50,   194,     9,   215,    82,\n",
      "          479,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([    0,   597,  3239,  2046,   121,   387,   128,    29,   810,  4392,\n",
      "           34,  2782,   511,    10,  3294,  1567,  2973,     7,  2514, 22997,\n",
      "         1626,    31,  7346, 15286,  2156,    61,    32,    55,  4478,    11,\n",
      "          776, 14013,    29,  2156,     8,   357,   810,  1052,   479,   152,\n",
      "          115,   323,   357,  3440,  1318,    87,    11,     5,   375,   479,\n",
      "          345,    34,    57,    10,  4406,  2991,    11,   121,   387,   128,\n",
      "           29,   431,  4200,   234,  7205,  1750,     7,   204,     4,  5677,\n",
      "          207,    23,   253,    12, 11983,   570,    31,   290,     4,  1244,\n",
      "          207,    23,   253,    12, 16310,   479,   152,  1955, 26807,   234,\n",
      "         7205,    29,    23,    63,  8540,   121,   387,  4090,  2156,    61,\n",
      "         2442,  1233,     8,  9521,    13,  2357,     4,   245,   207,     9,\n",
      "            5,  1134,   128,   746,   234,  7205,    29,    23,   253,    12,\n",
      "        11983,   570,   479,     2,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0)}]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "max_length = 300\n",
    "dataset = CustomDataset(X_train, y_train, tokenizer, max_length)\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "print(type(train_dataset))\n",
    "print(train_dataset[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
